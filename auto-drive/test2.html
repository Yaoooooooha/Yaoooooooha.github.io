<!DOCTYPE html>
<html lang="en">
  <head>
    <!-- 用戶不能調整大小 -->
    <meta
      charset="UTF-8"
      name="viewport"
      content="width=device-width, user-scalable=no, minimum-scale=1.0, maximum-scale=1.0, initial-scale=1"
    />
    <link rel="stylesheet" href="./style.css" />
    <title>AR Self-Driving Car Guided Tour</title>
    <script src="https://aframe.io/releases/1.3.0/aframe.min.js"></script>
    <!-- for image base (need to comment out "aframe-ar.js")
    <script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar-nft.js"></script> -->
    <script src="https://raw.githack.com/AR-js-org/AR.js/master/aframe/build/aframe-ar.js"></script>
    <script src="./sample.js"></script>
  </head>

  <body>
    <!-- 載入中的提示 -->
    <div class="arjs-loader">
      <div>Loading, please wait...</div>
    </div>
    <!-- 互動按鈕 -->
    <div class="control-button" id="play-video">
      <div>play</div>
    </div>
    <div class="control-button" id="video-sound">
      <div>sound on</div>
    </div>
    <div class="control-button" id="more-information">
      <div>info</div>
    </div>
    <div class="control-button" id="take-picture">
      <div>take picture</div>
    </div>

    <!-- for nft base 
    <a-scene
      vr-mode-ui="enabled: false;"
      renderer="antialias: true; alpha: true; precision: mediump;"
      embedded
      arjs="trackingMethod: best; sourceType: webcam; debugUIEnabled: false;"
    > -->

    <a-scene
      vr-mode-ui="enabled: false;"
      embedded
      arjs="sourceType: webcam; debugUIEnabled: false;"
    >
      <!-- for nft base 
      <a-nft
        pagehandler
        type="nft"
        url="https://Yaoooooooha.github.io/auto-drive/assets/image/Hiro_marker_ARjs"
        smooth="true"
        smoothCount="10"
        smoothTolerance="0.01"
        smoothThreshold="5"
      >

        <a-entity
          id="geo-plane"
          geometry="primitive: plane; width: 90; height: 90"
          material="src: #video"
          position="0 0 0"
          rotation="-90 0 0"
          animation="property: scale; from: 1 0 1; to: 1 1 1; dur: 500; loop: false; easing: linear; startEvents: geo-plane-scaled"
        ></a-entity>
      </a-nft> -->

      <!-- 偵測的圖片 -->
      <a-marker
        pagehandler
        type="pattern"
        url="https://Yaoooooooha.github.io/auto-drive/assets/pattern-marker.patt"
        smooth="true"
        smoothCount="5"
        smoothTolerance="0.01"
        smoothThreshold="2"
      >
        <!-- 顯示導覽影片 -->
        <a-entity
          id="geo-plane"
          geometry="primitive: plane; width: 2; height: 2"
          material="src: #video"
          position="0 -3 0"
          rotation="-90 0 0"
          animation="property: scale; from: 1 0 1; to: 1 1 1; dur: 500; loop: false; easing: linear; startEvents: geo-plane-scaled"
        ></a-entity>
        <a-box color="red" depth="1" height="1" width="1"></a-box>
      </a-marker>

      <!-- 影片檔案 -->
      <a-assets>
        <video
          id="video"
          src="https://Yaoooooooha.github.io/auto-drive/assets/your_video.mp4"
          autoplay="false"
          preload="auto"
          loop="true"
          webkit-playsinline
          playsinline
        ></video>
      </a-assets>
    </a-scene>
    <script>
      // 調整 canvas 大小

      function resizeCanvas(origCanvas, width, height) {
        let resizedCanvas = document.createElement("canvas");
        let resizedContext = resizedCanvas.getContext("2d");

        resizedCanvas.height = height;
        resizedCanvas.width = width;

        if (width > height) {
          // Landscape
          resizedContext.drawImage(origCanvas, 0, 0, width, height);
        } else {
          // Portrait
          resizedContext.drawImage(origCanvas, 0, 0, height, width);
        }

        return resizedCanvas.toDataURL();
      }

      // 抓取 ar 鏡頭的畫面
      function captureVideoFrame(video, format, width, height) {
        if (typeof video === "string") {
          video = document.querySelector(video);
          console.log(video);
        }

        format = format || "jpeg";

        if (!video || (format !== "png" && format !== "jpeg")) {
          return false;
        }

        var canvas = document.createElement("CANVAS");

        canvas.width = width || video.videoWidth;
        canvas.height = height || video.videoHeight;
        canvas.getContext("2d").drawImage(video, 0, 0);
        var dataUri = canvas.toDataURL("image/" + format);
        var data = dataUri.split(",")[1];
        var mimeType = dataUri.split(";")[0].slice(5);

        var bytes = window.atob(data);
        var buf = new ArrayBuffer(bytes.length);
        var arr = new Uint8Array(buf);

        for (var i = 0; i < bytes.length; i++) {
          arr[i] = bytes.charCodeAt(i);
        }

        var blob = new Blob([arr], { type: mimeType });
        return {
          blob: blob,
          dataUri: dataUri,
          format: format,
          width: canvas.width,
          height: canvas.height,
        };
      }

      // from https://github.com/lukechilds/merge-images
      var defaultOptions = {
        format: "image/png",
        quality: 0.92,
        width: undefined,
        height: undefined,
        Canvas: undefined,
        crossOrigin: undefined,
      };

      // from https://github.com/lukechilds/merge-images
      // 合併 3d 模型和 ar 鏡頭的畫面
      var mergeImages = function (sources, options) {
        if (sources === void 0) sources = [];
        if (options === void 0) options = {};

        return new Promise(function (resolve) {
          options = Object.assign({}, defaultOptions, options);

          // Setup browser/Node.js specific variables
          var canvas = options.Canvas
            ? new options.Canvas()
            : window.document.createElement("canvas");
          var Image = options.Image || window.Image;

          // Load sources
          var images = sources.map(function (source) {
            return new Promise(function (resolve, reject) {
              // Convert sources to objects
              if (source.constructor.name !== "Object") {
                source = { src: source };
              }

              // Resolve source and img when loaded
              var img = new Image();
              img.crossOrigin = options.crossOrigin;
              img.onerror = function () {
                return reject(new Error("Couldn't load image"));
              };
              img.onload = function () {
                return resolve(Object.assign({}, source, { img: img }));
              };
              img.src = source.src;
            });
          });

          // Get canvas context
          var ctx = canvas.getContext("2d");

          // When sources have loaded
          resolve(
            Promise.all(images).then(function (images) {
              // Set canvas dimensions
              var getSize = function (dim) {
                return (
                  options[dim] ||
                  Math.max.apply(
                    Math,
                    images.map(function (image) {
                      return image.img[dim];
                    })
                  )
                );
              };
              canvas.width = getSize("width");
              canvas.height = getSize("height");

              // Draw images to canvas
              images.forEach(function (image) {
                ctx.globalAlpha = image.opacity ? image.opacity : 1;
                return ctx.drawImage(image.img, image.x || 0, image.y || 0);
              });

              if (options.Canvas && options.format === "image/jpeg") {
                // Resolve data URI for node-canvas jpeg async
                return new Promise(function (resolve, reject) {
                  canvas.toDataURL(
                    options.format,
                    {
                      quality: options.quality,
                      progressive: false,
                    },
                    function (err, jpeg) {
                      if (err) {
                        reject(err);
                        return;
                      }
                      resolve(jpeg);
                    }
                  );
                });
              }

              // Resolve all other data URIs sync
              return canvas.toDataURL(options.format, options.quality);
            })
          );
        });
      };

      // 點按拍攝鍵後拍照
      let screenshotBtn = document.getElementById("take-picture");
      screenshotBtn.addEventListener("click", function () {
        // 使用 a-frame 內建的截圖功能(只截的到 3D 模型)
        let aScene = document
          .querySelector("a-scene")
          .components.screenshot.getCanvas("perspective");
        // 抓取 ar 視訊鏡頭的畫面，然後繪製到 canva 上變成圖片
        let frame = captureVideoFrame("#arjs-video", "png");
        aScene = resizeCanvas(aScene, frame.width, frame.height);
        frame = frame.dataUri;
        mergeImages([frame, aScene]).then((b64) => {
          // 建造一個臨時下載點
          let link = document.createElement("a");
          link.setAttribute("download", "AR.png");
          link.setAttribute("href", b64);
          // 將臨時元素添加到文檔中
          document.body.appendChild(link);
          // 模擬典籍下載連結
          link.click();
          // 移除臨時元素
          document.body.removeChild(link);
        });
      });
    </script>
  </body>
</html>
